{"ast":null,"code":"/** internal\n * class ParserInline\n *\n * Tokenizes paragraph content.\n **/\n'use strict';\n\nvar Ruler = require('./ruler');\n\n////////////////////////////////////////////////////////////////////////////////\n// Parser rules\n\nvar _rules = [['text', require('./rules_inline/text')], ['newline', require('./rules_inline/newline')], ['escape', require('./rules_inline/escape')], ['backticks', require('./rules_inline/backticks')], ['strikethrough', require('./rules_inline/strikethrough')], ['emphasis', require('./rules_inline/emphasis')], ['link', require('./rules_inline/link')], ['image', require('./rules_inline/image')], ['autolink', require('./rules_inline/autolink')], ['html_inline', require('./rules_inline/html_inline')], ['entity', require('./rules_inline/entity')]];\n\n/**\n * new ParserInline()\n **/\nfunction ParserInline() {\n  /**\n   * ParserInline#ruler -> Ruler\n   *\n   * [[Ruler]] instance. Keep configuration of inline rules.\n   **/\n  this.ruler = new Ruler();\n  for (var i = 0; i < _rules.length; i++) {\n    this.ruler.push(_rules[i][0], _rules[i][1]);\n  }\n}\n\n// Skip single token by running all rules in validation mode;\n// returns `true` if any rule reported success\n//\nParserInline.prototype.skipToken = function (state) {\n  var i,\n    pos = state.pos,\n    rules = this.ruler.getRules(''),\n    len = rules.length,\n    maxNesting = state.md.options.maxNesting,\n    cache = state.cache;\n  if (typeof cache[pos] !== 'undefined') {\n    state.pos = cache[pos];\n    return;\n  }\n\n  /*istanbul ignore else*/\n  if (state.level < maxNesting) {\n    for (i = 0; i < len; i++) {\n      if (rules[i](state, true)) {\n        cache[pos] = state.pos;\n        return;\n      }\n    }\n  }\n  state.pos++;\n  cache[pos] = state.pos;\n};\n\n// Generate tokens for input range\n//\nParserInline.prototype.tokenize = function (state) {\n  var ok,\n    i,\n    rules = this.ruler.getRules(''),\n    len = rules.length,\n    end = state.posMax,\n    maxNesting = state.md.options.maxNesting;\n  while (state.pos < end) {\n    // Try all possible rules.\n    // On success, rule should:\n    //\n    // - update `state.pos`\n    // - update `state.tokens`\n    // - return true\n\n    if (state.level < maxNesting) {\n      for (i = 0; i < len; i++) {\n        ok = rules[i](state, false);\n        if (ok) {\n          break;\n        }\n      }\n    }\n    if (ok) {\n      if (state.pos >= end) {\n        break;\n      }\n      continue;\n    }\n    state.pending += state.src[state.pos++];\n  }\n  if (state.pending) {\n    state.pushPending();\n  }\n};\n\n/**\n * ParserInline.parse(str, md, env, outTokens)\n *\n * Process input string and push inline tokens into `outTokens`\n **/\nParserInline.prototype.parse = function (str, md, env, outTokens) {\n  var state = new this.State(str, md, env, outTokens);\n  this.tokenize(state);\n};\nParserInline.prototype.State = require('./rules_inline/state_inline');\nmodule.exports = ParserInline;","map":{"version":3,"names":["Ruler","require","_rules","ParserInline","ruler","i","length","push","prototype","skipToken","state","pos","rules","getRules","len","maxNesting","md","options","cache","level","tokenize","ok","end","posMax","pending","src","pushPending","parse","str","env","outTokens","State","module","exports"],"sources":["E:/Projects/ASPHENIX/Pokedex-AI-v1/node_modules/markdown-it/lib/parser_inline.js"],"sourcesContent":["/** internal\n * class ParserInline\n *\n * Tokenizes paragraph content.\n **/\n'use strict';\n\n\nvar Ruler           = require('./ruler');\n\n\n////////////////////////////////////////////////////////////////////////////////\n// Parser rules\n\nvar _rules = [\n  [ 'text',            require('./rules_inline/text') ],\n  [ 'newline',         require('./rules_inline/newline') ],\n  [ 'escape',          require('./rules_inline/escape') ],\n  [ 'backticks',       require('./rules_inline/backticks') ],\n  [ 'strikethrough',   require('./rules_inline/strikethrough') ],\n  [ 'emphasis',        require('./rules_inline/emphasis') ],\n  [ 'link',            require('./rules_inline/link') ],\n  [ 'image',           require('./rules_inline/image') ],\n  [ 'autolink',        require('./rules_inline/autolink') ],\n  [ 'html_inline',     require('./rules_inline/html_inline') ],\n  [ 'entity',          require('./rules_inline/entity') ]\n];\n\n\n/**\n * new ParserInline()\n **/\nfunction ParserInline() {\n  /**\n   * ParserInline#ruler -> Ruler\n   *\n   * [[Ruler]] instance. Keep configuration of inline rules.\n   **/\n  this.ruler = new Ruler();\n\n  for (var i = 0; i < _rules.length; i++) {\n    this.ruler.push(_rules[i][0], _rules[i][1]);\n  }\n}\n\n\n// Skip single token by running all rules in validation mode;\n// returns `true` if any rule reported success\n//\nParserInline.prototype.skipToken = function (state) {\n  var i, pos = state.pos,\n      rules = this.ruler.getRules(''),\n      len = rules.length,\n      maxNesting = state.md.options.maxNesting,\n      cache = state.cache;\n\n\n  if (typeof cache[pos] !== 'undefined') {\n    state.pos = cache[pos];\n    return;\n  }\n\n  /*istanbul ignore else*/\n  if (state.level < maxNesting) {\n    for (i = 0; i < len; i++) {\n      if (rules[i](state, true)) {\n        cache[pos] = state.pos;\n        return;\n      }\n    }\n  }\n\n  state.pos++;\n  cache[pos] = state.pos;\n};\n\n\n// Generate tokens for input range\n//\nParserInline.prototype.tokenize = function (state) {\n  var ok, i,\n      rules = this.ruler.getRules(''),\n      len = rules.length,\n      end = state.posMax,\n      maxNesting = state.md.options.maxNesting;\n\n  while (state.pos < end) {\n    // Try all possible rules.\n    // On success, rule should:\n    //\n    // - update `state.pos`\n    // - update `state.tokens`\n    // - return true\n\n    if (state.level < maxNesting) {\n      for (i = 0; i < len; i++) {\n        ok = rules[i](state, false);\n        if (ok) { break; }\n      }\n    }\n\n    if (ok) {\n      if (state.pos >= end) { break; }\n      continue;\n    }\n\n    state.pending += state.src[state.pos++];\n  }\n\n  if (state.pending) {\n    state.pushPending();\n  }\n};\n\n\n/**\n * ParserInline.parse(str, md, env, outTokens)\n *\n * Process input string and push inline tokens into `outTokens`\n **/\nParserInline.prototype.parse = function (str, md, env, outTokens) {\n  var state = new this.State(str, md, env, outTokens);\n\n  this.tokenize(state);\n};\n\n\nParserInline.prototype.State = require('./rules_inline/state_inline');\n\n\nmodule.exports = ParserInline;\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA,YAAY;;AAGZ,IAAIA,KAAK,GAAaC,OAAO,CAAC,SAAS,CAAC;;AAGxC;AACA;;AAEA,IAAIC,MAAM,GAAG,CACX,CAAE,MAAM,EAAaD,OAAO,CAAC,qBAAqB,CAAC,CAAE,EACrD,CAAE,SAAS,EAAUA,OAAO,CAAC,wBAAwB,CAAC,CAAE,EACxD,CAAE,QAAQ,EAAWA,OAAO,CAAC,uBAAuB,CAAC,CAAE,EACvD,CAAE,WAAW,EAAQA,OAAO,CAAC,0BAA0B,CAAC,CAAE,EAC1D,CAAE,eAAe,EAAIA,OAAO,CAAC,8BAA8B,CAAC,CAAE,EAC9D,CAAE,UAAU,EAASA,OAAO,CAAC,yBAAyB,CAAC,CAAE,EACzD,CAAE,MAAM,EAAaA,OAAO,CAAC,qBAAqB,CAAC,CAAE,EACrD,CAAE,OAAO,EAAYA,OAAO,CAAC,sBAAsB,CAAC,CAAE,EACtD,CAAE,UAAU,EAASA,OAAO,CAAC,yBAAyB,CAAC,CAAE,EACzD,CAAE,aAAa,EAAMA,OAAO,CAAC,4BAA4B,CAAC,CAAE,EAC5D,CAAE,QAAQ,EAAWA,OAAO,CAAC,uBAAuB,CAAC,CAAE,CACxD;;AAGD;AACA;AACA;AACA,SAASE,YAAYA,CAAA,EAAG;EACtB;AACF;AACA;AACA;AACA;EACE,IAAI,CAACC,KAAK,GAAG,IAAIJ,KAAK,CAAC,CAAC;EAExB,KAAK,IAAIK,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGH,MAAM,CAACI,MAAM,EAAED,CAAC,EAAE,EAAE;IACtC,IAAI,CAACD,KAAK,CAACG,IAAI,CAACL,MAAM,CAACG,CAAC,CAAC,CAAC,CAAC,CAAC,EAAEH,MAAM,CAACG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;EAC7C;AACF;;AAGA;AACA;AACA;AACAF,YAAY,CAACK,SAAS,CAACC,SAAS,GAAG,UAAUC,KAAK,EAAE;EAClD,IAAIL,CAAC;IAAEM,GAAG,GAAGD,KAAK,CAACC,GAAG;IAClBC,KAAK,GAAG,IAAI,CAACR,KAAK,CAACS,QAAQ,CAAC,EAAE,CAAC;IAC/BC,GAAG,GAAGF,KAAK,CAACN,MAAM;IAClBS,UAAU,GAAGL,KAAK,CAACM,EAAE,CAACC,OAAO,CAACF,UAAU;IACxCG,KAAK,GAAGR,KAAK,CAACQ,KAAK;EAGvB,IAAI,OAAOA,KAAK,CAACP,GAAG,CAAC,KAAK,WAAW,EAAE;IACrCD,KAAK,CAACC,GAAG,GAAGO,KAAK,CAACP,GAAG,CAAC;IACtB;EACF;;EAEA;EACA,IAAID,KAAK,CAACS,KAAK,GAAGJ,UAAU,EAAE;IAC5B,KAAKV,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGS,GAAG,EAAET,CAAC,EAAE,EAAE;MACxB,IAAIO,KAAK,CAACP,CAAC,CAAC,CAACK,KAAK,EAAE,IAAI,CAAC,EAAE;QACzBQ,KAAK,CAACP,GAAG,CAAC,GAAGD,KAAK,CAACC,GAAG;QACtB;MACF;IACF;EACF;EAEAD,KAAK,CAACC,GAAG,EAAE;EACXO,KAAK,CAACP,GAAG,CAAC,GAAGD,KAAK,CAACC,GAAG;AACxB,CAAC;;AAGD;AACA;AACAR,YAAY,CAACK,SAAS,CAACY,QAAQ,GAAG,UAAUV,KAAK,EAAE;EACjD,IAAIW,EAAE;IAAEhB,CAAC;IACLO,KAAK,GAAG,IAAI,CAACR,KAAK,CAACS,QAAQ,CAAC,EAAE,CAAC;IAC/BC,GAAG,GAAGF,KAAK,CAACN,MAAM;IAClBgB,GAAG,GAAGZ,KAAK,CAACa,MAAM;IAClBR,UAAU,GAAGL,KAAK,CAACM,EAAE,CAACC,OAAO,CAACF,UAAU;EAE5C,OAAOL,KAAK,CAACC,GAAG,GAAGW,GAAG,EAAE;IACtB;IACA;IACA;IACA;IACA;IACA;;IAEA,IAAIZ,KAAK,CAACS,KAAK,GAAGJ,UAAU,EAAE;MAC5B,KAAKV,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGS,GAAG,EAAET,CAAC,EAAE,EAAE;QACxBgB,EAAE,GAAGT,KAAK,CAACP,CAAC,CAAC,CAACK,KAAK,EAAE,KAAK,CAAC;QAC3B,IAAIW,EAAE,EAAE;UAAE;QAAO;MACnB;IACF;IAEA,IAAIA,EAAE,EAAE;MACN,IAAIX,KAAK,CAACC,GAAG,IAAIW,GAAG,EAAE;QAAE;MAAO;MAC/B;IACF;IAEAZ,KAAK,CAACc,OAAO,IAAId,KAAK,CAACe,GAAG,CAACf,KAAK,CAACC,GAAG,EAAE,CAAC;EACzC;EAEA,IAAID,KAAK,CAACc,OAAO,EAAE;IACjBd,KAAK,CAACgB,WAAW,CAAC,CAAC;EACrB;AACF,CAAC;;AAGD;AACA;AACA;AACA;AACA;AACAvB,YAAY,CAACK,SAAS,CAACmB,KAAK,GAAG,UAAUC,GAAG,EAAEZ,EAAE,EAAEa,GAAG,EAAEC,SAAS,EAAE;EAChE,IAAIpB,KAAK,GAAG,IAAI,IAAI,CAACqB,KAAK,CAACH,GAAG,EAAEZ,EAAE,EAAEa,GAAG,EAAEC,SAAS,CAAC;EAEnD,IAAI,CAACV,QAAQ,CAACV,KAAK,CAAC;AACtB,CAAC;AAGDP,YAAY,CAACK,SAAS,CAACuB,KAAK,GAAG9B,OAAO,CAAC,6BAA6B,CAAC;AAGrE+B,MAAM,CAACC,OAAO,GAAG9B,YAAY","ignoreList":[]},"metadata":{},"sourceType":"script","externalDependencies":[]}